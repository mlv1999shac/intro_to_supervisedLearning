# intro_to_supervisedLearning

Includes classification and regression techniques with examples ranging from telecom churn , salary data , and creating own random data sets ,
using datasets like iris dataset , boston house details and applying classfication techiques like naive bayes, SVM , decision trees
and implementing ensemble methods like random forest, ada boost . 
Here we are also tuning various parameters to avoid overfitting and comapring algorithms to figure out best suited algorithm.
Computational learning theory is a brach where you actually have n hypthosis and figure out best suited hypothesis and deal with sample complexity.
Choosing best hypothies is done based on probability of how hypothesis is performing over data . We apply bayesian rule for that and
thats one of the application of bayesian learning.
Soon i will come up how to code linear regression , Knn , Artifical neural networks , and SVM from scratch with a seperate repository.

Then there are few examples how linear regression and other types of regressions like Lassco , rigde regression and basically plotting all the 
graohs using seaborn lmplot to view the polynomial regression visually and then making content out of it .

